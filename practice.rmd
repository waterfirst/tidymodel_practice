
library(tidyverse)
library(tidymodels)
library(lubridate)
# Helper packages
library(readr)       # for importing data
library(vip) 

hotels <-  read.csv("D:/Non_Documents/AI/R/data/hotels.csv", stringsAsFactors=TRUE)
#  read_csv('https://tidymodels.org/start/case-study/hotels.csv') %>%

#children : none, children (2종 분류 예측)

hotels %>% 
  count(children) %>% 
  mutate(prop = n/sum(n))

hotels %>% 
  mutate(arrival_date = lubridate::as_date(arrival_date)) -> hotels

#총 5000개 데이터 중 8% 정도만 아이가 있고 나머지는 없음

set.seed(123)
splits      <- initial_split(hotels, strata = children)

hotel_train <- training(splits)
hotel_test  <- testing(splits)


hotel_train %>% 
  count(children) %>% 
  mutate(prop = n/sum(n))

hotel_test  %>% 
  count(children) %>% 
  mutate(prop = n/sum(n))

#총 train, test 에 각각 8% 수준으로 아이가 있도록 잘 분류됨


#train 데이터 중 일부를 떼어서 검증용 데이터를 만듦
set.seed(234)
val_set <- validation_split(hotel_train, 
                            strata = children, 
                            prop = 0.80)
val_set



#로지스틱 회귀 분석

# 1. 모델 선언  (glmnet)

lr_mod <- 
  logistic_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")


# 2. 레시피 만들기

holidays <- c("AllSouls", "AshWednesday", "ChristmasEve", "Easter", 
              "ChristmasDay", "GoodFriday", "NewYearsDay", "PalmSunday")

lr_recipe <- 
  recipe(children ~ ., data = hotel_train) %>% 
  step_date(arrival_date) %>% 
  step_holiday(arrival_date, holidays = holidays) %>% 
  step_rm(arrival_date) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors())


# 3. 워크 플로우 만들기 (전처리데이터/모델)

lr_workflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(lr_recipe)

# 4. 하이퍼 파라미터 튜닝
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))

lr_reg_grid %>% top_n(-5) # lowest penalty values


#5. 모델 학습
lr_res <- 
  lr_workflow %>% 
  tune_grid(val_set,
            grid = lr_reg_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))


#6. 파라미터 (패널티 값)에 따른 ROC 곡선
lr_plot <- 
  lr_res %>% 
  collect_metrics() %>% 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab("Area under the ROC Curve") +
  scale_x_log10(labels = scales::label_number())

lr_plot #penalty가 작을수록 ROC값이 크다

#7. best 파라미터로 최종 모델 다시 만들기
top_models <-
  lr_res %>% 
  show_best("roc_auc", n = 15) %>% 
  arrange(penalty) 
top_models

#최적 파라미터 값 알기
lr_best <- 
  lr_res %>% 
  collect_metrics() %>% 
  arrange(penalty) %>% 
  slice(12)
lr_best


#최종모델로 roc커브 그리기
lr_auc <- 
  lr_res %>% 
  collect_predictions(parameters = lr_best) %>% 
  roc_curve(children, .pred_children) %>% 
  mutate(model = "Logistic Regression")

autoplot(lr_auc)



############앙상블 모델/ 병렬 처리 ##############################################

cores <- parallel::detectCores()
cores

#1. 랜덤포레스트, 분류 모델 선언하기

rf_mod <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_engine("ranger", num.threads = cores) %>% 
  set_mode("classification")


#2. 레시피 만들기
rf_recipe <- 
  recipe(children ~ ., data = hotel_train) %>% 
  step_date(arrival_date) %>% 
  step_holiday(arrival_date) %>% 
  step_rm(arrival_date) 

#3. 워크 플로우 만들기
rf_workflow <- 
  workflow() %>% 
  add_model(rf_mod) %>% 
  add_recipe(rf_recipe)

rf_mod
extract_parameter_set_dials(rf_mod)

#4. 하이퍼 파라미터 최적화(mtry 갯수), roc_auc를 기반으로 최대값 찾기
set.seed(345)
rf_res <- 
  rf_workflow %>% 
  tune_grid(val_set,
            grid = 25,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))

#5. best 파라미터 보기
rf_res %>% 
  show_best(metric = "roc_auc")

#6. mtry 값에 따라 roc_auc 보기
autoplot(rf_res)

#7. 최적 파라미터 찾기
rf_best <- 
  rf_res %>% 
  select_best(metric = "roc_auc")
rf_best

#8. 최적 모델로 예측하기 (.pred_children)
rf_res %>% 
  collect_predictions()


#9. 랜덤포레스트 값 저장하기

rf_auc <- 
  rf_res %>% 
  collect_predictions(parameters = rf_best) %>% 
  roc_curve(children, .pred_children) %>% 
  mutate(model = "Random Forest")



#10. 로지스틱 회귀분석과 랜덤포레스트 ROC_Curve 비교하기
bind_rows(rf_auc, lr_auc) %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + 
  geom_path(lwd = 1.5, alpha = 0.8) +
  geom_abline(lty = 3) + 
  coord_equal() + 
  scale_color_viridis_d(option = "plasma", end = .6)


#11. 최적모델 만들기

# the last model
last_rf_mod <- 
  rand_forest(mtry = 8, min_n = 7, trees = 1000) %>% 
  set_engine("ranger", num.threads = cores, importance = "impurity") %>% 
  set_mode("classification")

# the last workflow
last_rf_workflow <- 
  rf_workflow %>% 
  update_model(last_rf_mod)

# the last fit
set.seed(345)
last_rf_fit <- 
  last_rf_workflow %>% 
  last_fit(splits)

last_rf_fit


#12. 테스트 셋 예측하기
last_rf_fit %>% 
  collect_metrics()



#13. 랜덤포레스트 중요도 보기 (객실 일일비용이 가장 중요 변수)
last_rf_fit %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 20)


#14.최종적으로 테스트 셋을 이용하여 예측한 children 값과 실제값을 이용하여 roc_curve 그리기

last_rf_fit %>% 
  collect_predictions() %>% 
  roc_curve(children, .pred_children) %>% 
  autoplot()
